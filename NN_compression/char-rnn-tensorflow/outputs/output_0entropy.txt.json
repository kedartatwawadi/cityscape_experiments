{
  "grad_clip": 5.0, 
  "vocab_size": 1, 
  "last_epoch_loss": 0.0, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_1_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 1, 
  "epoch_stopped": 1, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_1_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 1, 
  "last_epoch_loss": 0.0, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_2_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 2, 
  "epoch_stopped": 1, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_2_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0084550006351149717, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_3_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 3, 
  "epoch_stopped": 4, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_3_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0090391201759752945, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_4_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 4, 
  "epoch_stopped": 6, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_4_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0092472677929711696, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_5_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 5, 
  "epoch_stopped": 7, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_5_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0092796024333875998, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_6_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 6, 
  "epoch_stopped": 9, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_6_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0086015878851983703, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_7_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 7, 
  "epoch_stopped": 11, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_7_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0075039077868044382, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_8_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 8, 
  "epoch_stopped": 13, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_8_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0093681490196060053, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_9_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 9, 
  "epoch_stopped": 9, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_9_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0087513223296178562, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_10_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 10, 
  "epoch_stopped": 22, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_10_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0099176069036698688, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_11_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 11, 
  "epoch_stopped": 22, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_11_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0094645596154055971, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_12_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 12, 
  "epoch_stopped": 28, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_12_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0089729870376854017, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_13_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 13, 
  "epoch_stopped": 27, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_13_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.008640842148480694, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_14_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 14, 
  "epoch_stopped": 33, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_14_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0082445198924920634, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_15_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 15, 
  "epoch_stopped": 37, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_15_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0094675368089221518, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_16_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 16, 
  "epoch_stopped": 20, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_16_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0099032943917882563, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_17_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 17, 
  "epoch_stopped": 28, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_17_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0094555520009732795, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_18_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 18, 
  "epoch_stopped": 43, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_18_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.022829128383312584, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_19_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 19, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_19_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.021328686899390169, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_20_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 20, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_20_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0099689531953349644, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_21_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 21, 
  "epoch_stopped": 46, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_21_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.059833511553533683, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_22_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 22, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_22_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.030927385388947654, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_23_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 23, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_23_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.1340503620209898, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_24_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 24, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_24_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.10625809583780106, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_25_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 25, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_25_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.14539844751981049, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_26_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 26, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_26_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.16059672326889451, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_27_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 27, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_27_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.1669805832951386, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_28_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 28, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_28_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.0002576929527556, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_29_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 29, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_29_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.47893115601613784, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_30_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 30, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_30_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.0000332383951145, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_31_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 31, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_31_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0097385143048535211, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_32_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 32, 
  "epoch_stopped": 29, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_32_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.0090971606068071496, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_33_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 33, 
  "epoch_stopped": 27, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_33_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.50789162416369771, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_34_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 34, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_34_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.45186183167018823, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_35_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 35, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_35_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.67442832614886317, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_36_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 36, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_36_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.75524863201851034, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_37_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 37, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_37_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.84777846588815176, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_38_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 38, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_38_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.75302170713957217, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_39_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 39, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_39_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.70440474418519028, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_40_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 40, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_40_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.97540450372418575, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_41_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 41, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_41_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.000043142446021, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_42_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 42, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_42_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.0000062887137242, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_43_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 43, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_43_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.99698552524004236, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_44_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 44, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_44_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.0001728861578321, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_45_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 45, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_45_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.0001488171858437, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_46_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 46, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_46_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.0003684992249231, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_47_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 47, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_47_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 1.0000740498781648, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_48_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 48, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_48_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.99433656460991104, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_49_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 49, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_49_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
{
  "grad_clip": 5.0, 
  "vocab_size": 2, 
  "last_epoch_loss": 0.99967263377191795, 
  "data_type": "0entropy", 
  "lower_bound": 0, 
  "learning_rate": 0.002, 
  "file_size": 100000, 
  "num_layers": 2, 
  "batch_size": 50, 
  "info_path": "data/sequence_data/info_0entropy_50_markovity.txt", 
  "num_epochs": 50, 
  "markovity": 50, 
  "epoch_stopped": 50, 
  "save_every": 1000, 
  "init_from": null, 
  "rnn_size": 128, 
  "p1": 0.5, 
  "Entropy": 0, 
  "seq_length": 50, 
  "decay_rate": 0.99, 
  "data_path": "data/sequence_data/input_0entropy_50_markovity.txt", 
  "save_dir": "save", 
  "output_path": "outputs/output_0entropy.txt", 
  "model": "lstm"
}
 ############################################# 
